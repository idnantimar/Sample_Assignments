---
title: "Statistical Computing Assignment"
author: "RAMIT NANDI || MD2211"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    df_print: kable
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      message = F,
                      warning = F,
                      fig.align = "center")
```


# **Problem Statement**

```{r }
knitr::include_graphics("Qn.JPEG")

```

# **Solution**

## Goal of the analysis : 
To check whether the temperature affects the probability of O-ring failure.

## EDA 

Below we provide a snap of the dataset.
```{r}
set.seed(2211)
library(ggplot2)

DATA=read.csv("challenger.csv",header = TRUE)
head(DATA)
DATA$Failure = factor(DATA$Failure,labels = c("Success","Crash"),levels = c(0,1))

```

Just by looking at the boxplots of 'temperature vs failure status' , lower temperature is more prone to mission crash.

```{r}
ggplot(DATA, aes(x = DATA$Failure, y = DATA$Temperature)) +
  geom_boxplot() +
  ggtitle("Boxplots of O-ring Failure vs Temperature") +
  xlab("") + ylab("Temperature")
```

We standardize the data before proceeding further, for simpler calculations.
```{r, echo=TRUE}
std_Temp = scale(DATA$Temperature)
DATA$Temperature = as.vector(std_Temp)

```

\
\


## CLASSICAL APPROACH 

Since we have a binary-response data, as a beginning we fit a Logistic Regression on response 'Failure Status' and covariate 'Temperature (standardized)'. 
```{r GLM,echo=TRUE}
Model_Logistic = glm(Failure ~ Temperature , data = DATA,
                     family = "binomial")
summary(Model_Logistic)
```

The summary output shows the coefficient for Temperature is significant at level 5%. i.e.- the effect of Temperature is significant on the probability of O-ring failure.

```{r,echo=TRUE}
Model_Null = glm(Failure ~ 1 , data = DATA, family = "binomial")

```

We can also compare AIC,BIC with the Null Model(intercept only, no Temperature) to check whether the improved fit (smaller deviance) is worth enough to add one more parameter in the model. As a rule of thumb - smaller the AIC,BIC better the model.

```{r,echo=TRUE}
AIC(Model_Logistic,Model_Null)
BIC(Model_Logistic,Model_Null)
```

Hence, we should not discard the Temperature information available. For a better visualization , we plot the predicted failure probability vs temperature below, along with the observations available.
```{r,out.width="80%"}
ggplot( DATA, aes(x=Temperature, y=as.numeric(Failure=="Crash"))) +
geom_point() +
geom_smooth(method = "glm",
method.args = list(family = "binomial"),
) +
labs(title = "Temperature vs Failure Probability",
     x = "Temperature (standardized)",y = "Failure")

```

The plot suggests that the failure probability rises with decreasing temperature.




\
\


## BAYESIAN APPROACH 

After the frequentist exploration, now we move on to the Bayesian paradigm. We write the logistic model as :

$$P(Y_{i}=1|x_{i})=\frac{e^{\beta_{0}+\beta_{1}x_{i}}}{1+e^{\beta_{0}+\beta_{1}x_{i}}}= \pi(x_{i}), \ i=1,2......n$$

where x is the normalized variable temperature during the launch and Y represents the indicator variable whether any of the O-rings failed or not.


The likelihood function of $\beta$ given the observed data y, X can be written as :

$$\begin{aligned} f\left(y_i \mid \boldsymbol{\beta}, x_i\right) & =\pi_i^{y_i}\left(1-\pi_i\right)^{1-y_i} \\ & =\left[\frac{e^{\beta_0+\beta_1 x_{ i}}}{1+e^{\beta_0+\beta_1 x_{i}}}\right]^{y_i}\left[\frac{1}{1+e^{\beta_0+\beta_1 x_{ i}}}\right]^{1-y_i}\end{aligned}$$

```{r, echo=TRUE}
## log-likelihood function ....
l_beta = function(beta,X,Y){
  # log-likelihood for i-th observation 
  l_i = function(y,x) dbinom(y,size=1,
                             prob=plogis(beta[1] + x*beta[2]),
                             log=TRUE)
  # for the whole dataset 
  Data = data.frame(Y,X)
  l = apply(Data,MARGIN=1,FUN=function(d) l_i(d[1],d[2]))
  return(sum(l))
}

## likelihood function ....
L_beta = function(beta,X,Y) exp(l_beta(beta,X,Y))
```


now, since we want to incorporate very much prior assumption about the coefficients $\beta_0,\beta_1$

  for $\beta_0$ assume uniform prior over the whole real line,
    
  for $beta_1$ we can use a Normal prior with mean= MLE(already obtained in the classical approach above) , but a very large standard deviation $\lambda$ to make it a diffused prior 

$$\pi(\beta) \propto 1 \times exp(-\frac1{2 \lambda^2}(\beta_1-\hat{\beta_1}_{;MLE})^2)$$


```{r,echo=TRUE}
b1_MLE = coef(Model_Logistic)[2] 

## log-prior density ....
log_prior.unnormalized = function(beta,lambda=20){
  dnorm(beta[2],mean=b1_MLE,sd=lambda,log=TRUE)
} 

```


Hence, the posterior of $\beta$ can be written as :

$$\pi(\beta\mid x,y) \propto \pi(\beta) f(y \mid \beta,x)$$

$$\pi(\beta\mid x,y) \propto exp(-\frac1{2 \lambda^2}(\beta_1-\hat{\beta_1}_{;MLE})^2) \prod_{i=1}^{n} \left[\frac{e^{\beta_0+\beta_1 x_{ i}}}{1+e^{\beta_0+\beta_1 x_{i}}}\right]^{y_i}\left[\frac{1}{1+e^{\beta_0+\beta_1 x_{ i}}}\right]^{1-y_i}$$

or, $\pi(\beta\mid x,y) = \frac{\tilde p(\beta)}{Z_{p}}$ where $Z_{p}$ denotes the intractable normalizing constant and $\tilde p(\beta)$ denotes the part given above that is easily computable.

```{r , echo=TRUE}
## log-posterior density of beta ....
log_posterior.unnormalized = function(beta){
  l_beta(beta,
         X=DATA$Temperature,Y=as.numeric(DATA$Failure=="Crash")) +
    log_prior.unnormalized(beta)

}


```




Now, in order to draw samples from this posterior distribution of $\beta$, we use the following MCMC algorithm.

- We have to draw samples from the posterior distribution of $\beta$ which can be written as $p(\beta) = \pi(\beta\mid x,y)$


-  Now, we select our proposal distribution as $q(\beta\mid\beta^{(\tau)})$
where $\beta^{(\tau)}$
is the current iterate of $\beta$.
For implementing the basic Markov Chain Monte Carlo, we choose, q () to be a symmetric
distribution i.e.,

$$q(\beta\mid\beta^{(\tau)}\sim N_{2}(\beta^{(\tau)},\Sigma)$$

which is a bivariate normal density with mean $\beta^{(\tau)}$
and variance covariance matrix $\Sigma$. We take $\Sigma$ = diag ($\sigma_{1},\sigma_{2}$) where $\sigma_{i}$ are chosen in such a manner that the target distribution is neither explored too slowly such that it gets stuck in a mode even if the posterior is multimodal, nor too large that the acceptance probbility becomes too low.

- Finally, in an iteration $\tau$, where current value is $\beta^{(\tau)}$, we select a new value $\beta^{*}$ if $u<A(\beta^{*},\beta^{(\tau)})$, where 

  - $u\sim U(0,1)$ is an unifrom random sample.

  - $A(\beta^{*},\beta^{(\tau)})$ is the acceptance probability defined as $A(\beta^{*},\beta^{(\tau)}) = min (1, \frac{\tilde p(\beta^{*})}{\tilde p(\beta^{(\tau)})})$

  - then we set $\beta^{(\tau+1)} = \beta^{*}$ and proceed.

- Otherwise also we set $\beta^{(\tau+1)} = \beta^{(\tau)}$
and draw samples from proposal distribution $q(\beta\mid\beta^{(\tau +1)})$.

We draw B = $5 \times 10^{4}$ many samples from the posterior distribution using MCMC algorithm devised above and burn the first 10% samples also use a thinning gap of 5 to avoid significant correlations between the observations. 


```{r POSTERIOR MCMC, echo=TRUE}
## MLE estimates as the initialization of MCMC ....
beta.init = coef(Model_Logistic)


## Running the MCMC Sampler ....
library(MfUSampler)
N_samp = 5e+4
sample_beta.posterior = MfU.Sample.Run(beta.init,
                                       f=log_posterior.unnormalized,
                                       nsmp=N_samp,
               uni.sampler="unimet")

```


```{r burnin, echo=TRUE}
## burn-in ....
burn = function(samp,burn.frac=0.1){
  burn.idx = seq(length(samp)*burn.frac)
  samp[-burn.idx]
}

sample_beta.posterior = apply(sample_beta.posterior,
                              MARGIN=2,FUN=burn)

```

```{r thinning, echo=TRUE}
## Thinning ....
thinning = function(samp,gap=5){
  select.idx = seq(from=1,to=length(samp),by=gap)
  samp[select.idx]
} 

sample_beta.posterior = apply(sample_beta.posterior,
                              MARGIN=2,FUN=thinning)


```


Now, using the generated posterior samples, we plot the posterior densities of $\beta$ individually.

```{r}
library(ggplot2)
sample_beta.posterior = data.frame(sample_beta.posterior)
names(sample_beta.posterior) <- c('b0','b1')
# Posterior distributions of beta0
ggplot(data = sample_beta.posterior,aes(x=b0)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
labs(title = bquote("Density Plot of" ~ beta[0]),x = bquote(beta[0]))
```

\newpage

```{r}
# Posterior distributions of beta1
ggplot(data = sample_beta.posterior,aes(x=b1)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
labs(title = bquote("Density Plot of" ~ beta[1]),x = bquote(beta[1]))
```

We can compare the posterior means the Logistic Regression coefficients already available.

```{r,include=TRUE,warning=FALSE,message=FALSE}
m1 = apply(sample_beta.posterior, 2, mean)
m2 = Model_Logistic$coefficients
data.frame("Posterior.Means" = m1,"Logistic.Coef" = m2)
```

\newpage

To know whether these estimates are more or less consistent or not (ergodicity) we plot the cumulative means of these posterior samples.

```{r,echo=TRUE}
# plotting the mean cumulatively w.r.t sample size
b0.mean.cum <- cumsum(sample_beta.posterior$b0)/(1:nrow(sample_beta.posterior))
b1.mean.cum <- cumsum(sample_beta.posterior$b1)/(1:nrow(sample_beta.posterior))
```

```{r}
# plot of means with increasing sample size
plot(b0.mean.cum,type = "l",main = bquote("posterior mean of " ~ beta[0]),
xlab = "sample size",ylab = "mean")
```



```{r,include=TRUE,warning=FALSE,message=FALSE}
plot(b1.mean.cum,type = "l",main = bquote("posterior mean of " ~ beta[1]),
xlab = "sample size",ylab = "mean")
```

With increasing sample size, we can see that the mean more or less gets stabilized indicating their consistency.

Hereâ€™s another plot which may provide better idea through bivariate density plots taking two variables at a time where the density is shown using varying colour density.

```{r}
# b0,b1
ggplot(sample_beta.posterior, aes(x = b0, y = b1, fill = ..level..)) +
stat_density_2d(geom = "polygon") +
labs(title = bquote("Joint Density of" ~ beta[0] ~ "&" ~ beta[1]),
x = bquote(beta[0]), y = bquote(beta[1]))
```


As we see, the region with the highest density is away from $\beta_1=0$ , so with a certain high confidence we can say , HDP credible interval of $\beta_1$ excludes 0 , so Temperature affects failure probability.



We can also formally test the Hypothesis 
$$\boldsymbol{H_0}:\beta_1=0 \text{ vs } \boldsymbol{H_1}: \beta_1\neq0$$
using bayes factor, defined as $BF_{10} = \frac{m_{1}(X,y)}{m_{0}(X,y)}$.

We know $m_{i}(X,y) = \int f_{i}(y \mid \beta,X) \pi_{i}(\beta) d\beta$ for i=0,1 is the marginal likelihood under $\boldsymbol{H_i}$. Since the integration is hard to evaluate , we can approximate it by Harmonic Mean Estimator
$$\hat{m_i} = \left[\frac{1}{N} \sum_{j=1}^N \frac{1}{f_i \left( \boldsymbol{y} \mid \boldsymbol{\beta}^{(j)},\boldsymbol{X} \right)}\right]_{\boldsymbol{\beta}^{(j)} \sim \pi_{i}(\boldsymbol{\beta} \mid \boldsymbol{X}, \boldsymbol{y})}^{-1} ; i=0,1$$

```{r,echo=TRUE}
hat.m_i = function(likelihood.fn,Beta.values){
  L = apply(Beta.values,MARGIN=1,
            FUN=likelihood.fn)
  psych::harmonic.mean(L)
}
```


For $\hat{m_1}$ , we use the posterior samples of $\boldsymbol{\beta}$ already obtained , and estimate the marginal likelihood as
```{r m1, echo=TRUE}
m_1 = hat.m_i(function(beta) L_beta(beta,
         X=DATA$Temperature,Y=as.numeric(DATA$Failure=="Crash")),
         Beta.values=sample_beta.posterior)
```


Similarly , under $\boldsymbol{H_0}:\beta_1=0$
```{r H0,echo=TRUE}
## posterior density of beta ....
log_posterior.unnormalized.null = function(b0){
  # log-likelihood part 
  l_beta(c(b0,0),
         X=DATA$Temperature,
         Y=as.numeric(DATA$Failure=="Crash")) 
  # the log-prior density part is 0 ,
    #since we are using uniform  non-informative prior
}
 
## MCMC Sampler ....
sample_beta.posterior.null = MfU.Sample.Run(coef(Model_Null),
                                       f=log_posterior.unnormalized.null,
                                       nsmp=N_samp)
sample_beta.posterior.null = burn(sample_beta.posterior.null)
sample_beta.posterior.null = thinning(sample_beta.posterior.null)

## marginal likelihood ....
m_0 = hat.m_i(function(beta) L_beta(beta,
         X=DATA$Temperature,Y=as.numeric(DATA$Failure=="Crash")),
         Beta.values=data.frame(sample_beta.posterior.null,
                                vector("integer",
                                       length(sample_beta.posterior.null))))

```

Hence the Bayes Factor $BF_{10}$ is given by 
```{r,echo=TRUE}
(BF = m_1/m_0)

```
Since $BF_{10}>1$, It suggests we have strong evidence against the null hypothesis, so Temperature affects the failure probability.

\

The most important thing to visualize now, is how we can model the posterior probability distribution of that $\pi(y|X)= P(Y=1|X)={e^{\beta_0+\beta_1x}}/{(1+e^{\beta_0+\beta_1x})}$ We use the sampled posterior values of $\beta$ to plot the approximate distribution of $\pi(y|X)$
for some fixed value of x1. To see how the failure probability depends on x1 we take different values and then plot it.

To see how the posterior mean of failure probability changes with changing values of tempareture we calculate and several points and then plot them joining by a line :

```{r,include=TRUE,warning=FALSE,message=FALSE}
## Computing posterior probability P[Y=1|x] ....
Post.Prob1 = function(x.on_std_scale,Beta.values){

  Pi.Posterior = apply(Beta.values,MARGIN=1,
        FUN=function(beta) plogis(beta[1]+x.on_std_scale*beta[2]))
  return(Pi.Posterior)
}

temp.vals =-2:2
Pi.Posterior = sapply(temp.vals, function(x) Post.Prob1(x,sample_beta.posterior))
Pi.Posterior.mean = apply(Pi.Posterior,MARGIN=2,FUN=mean)
Pi.Posterior.sd = apply(Pi.Posterior,MARGIN=2,FUN=sd)


## Plotting ....
ggplot() +
geom_line(aes(x = temp.vals,y = Pi.Posterior.mean)) +
ylim(c(0,1)) +
geom_point(data = DATA,aes(x = Temperature,y = as.numeric(Failure=="Crash"))) +
geom_errorbar(aes(x = temp.vals,
                  ymin = Pi.Posterior.mean - Pi.Posterior.sd/2,
                  ymax = Pi.Posterior.mean + Pi.Posterior.sd/2),
linewidth=0.6, colour="blue", alpha=0.9
, size=1.3) +
labs(title = "Posterior Mean of Failure Probability with Error Bars",
x = "Tempareture",y = "Posterior Mean")
```

Based on the above figure we can conclude that, in the light of the given data it seems that cold temperature is more prone to O-ring failure. 


\
\

## An Intuitive MODEL-FREE APPROACH
Here we illustrate an alternative approach below, where we don't need any kind of Model assumption (unlike - binomial family for Logistic Regression etc). The underlying idea goes as follows - 

If a covariate X does not affect the response Y, it should happen that irrespective the response category , very similar X values are observed. We can say, conditional distribution of X given Y is same as marginal X distribution.
$$X|(Y=0) \stackrel{d}{=} X|(Y=1) \stackrel{d}{=} X$$

So , here we can group the Temperature(X) observations as per the Failure status (Y=0,1) and apply nonparametric 2-sample Kolmogorov-Smirnov (KS) test to check if there is any significant difference. Based on the p-value of this test we decide whether temperature affects failure probability or not , at a level of significance 5%. As per our interest we can also test the one-sided alternative of stochastic dominance that $X|(Y=1) \leq_{st} X|(Y=0)$

```{r,echo=TRUE}
Crash = subset(DATA$Temperature,DATA$Failure=="Crash")
Success = subset(DATA$Temperature,DATA$Failure!="Crash")

KS = ks.test(Crash,Success)
print(KS)

if(KS$p.value>=0.05){
  print("Temperature does not affect failure probability")
} else{
  cat("Temperature affects failure probability \n\n")
  
  KS.1sided = ks.test(Crash,Success,alternative='greater')
  print(KS.1sided)
  if(KS.1sided$p.value<0.05) cat("Less Temperature is more prone to O-ring failure \n")
}


```


## CONCLUSION 

Based on all the analysis we conclude that low temperature caused the crash of challenger.

